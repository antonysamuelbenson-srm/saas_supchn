{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20c6d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List, Optional\n",
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import RollingMean\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRMIST: Print statements to be replaced by logging. Whichever framework that you are using. \n",
    "# SRMIST: functions to be placed in relavant files. You can decide on that. \n",
    "\n",
    "data_api_type = 'csv' # \n",
    "\n",
    "data_column_mapping = {\n",
    "    \"ID\": [\"Store\"],\n",
    "    \"Date\": [\"Date\"],\n",
    "    \"Target\": [\"Weekly_Sales\"],\n",
    "    \"Regressor\": [\"Holiday_Flag\", \"Temperature\", \"Fuel_Price\", \"CPI\", \"Unemployment\"] # SRMIST: Ideally we should be able to pass an empty list and this should still work. \n",
    "}\n",
    "data_date_format_mapping = {\n",
    "    # \"Date\": [\"%d-%m-%Y\"],\n",
    "    \"Date\": [\"%Y-%m-%d\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297223de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTrainingData():\n",
    "\n",
    "    if (data_api_type == 'csv'):      # SRMIST: This is using a CSV. We must create options to connect to DB too based on input. \n",
    "        df = pl.read_csv('train.csv') # SRMIST: ensure actuals for the specified date is picked. \n",
    "    else:\n",
    "        print(f'Undefined data_api_type: {data_api_type}. Please provide valid data_api_type.')\n",
    "\n",
    "    return df\n",
    "\n",
    "def GetTestData():\n",
    "\n",
    "    if (data_api_type == 'csv'):\n",
    "        df = pl.read_csv('test.csv') # ensure actuals for the specified date is picked. \n",
    "    else:\n",
    "        print(f'Undefined data_api_type: {data_api_type}. Please provide valid data_api_type.')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff09844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def PreProcessDataType(df):\n",
    "\n",
    "    print(\"\\n--- Pre-processing Data Types ---\")\n",
    "    # Ensure Date columns are of type Date\n",
    "    if \"Date\" in data_column_mapping:\n",
    "        for col in data_column_mapping[\"Date\"]:\n",
    "            if col in df.columns:\n",
    "                # Check if the column is NOT already a Date type\n",
    "                if df[col].dtype != pl.Date:\n",
    "                    # Attempt to parse common date formats.\n",
    "                    date_format = data_date_format_mapping.get(col, [\"%Y-%m-%d\"])[0]\n",
    "                    df = df.with_columns(\n",
    "                        pl.col(col).str.strptime(pl.Date, strict=False, format=date_format).alias(col)\n",
    "                    )\n",
    "                    print(f\"  Converted '{col}' column to Date.\")\n",
    "                else:\n",
    "                    print(f\"  Column '{col}' is already a Date, skipping conversion.\")\n",
    "\n",
    "    # Ensure ID columns are of type String\n",
    "    if \"ID\" in data_column_mapping:\n",
    "        for col in data_column_mapping[\"ID\"]:\n",
    "            if col in df.columns:\n",
    "                df = df.with_columns(pl.col(col).cast(pl.String).alias(col))\n",
    "                print(f\"  Converted '{col}' to String.\")     \n",
    "\n",
    "    # Ensure Target and Regressor columns are of type Float64\n",
    "    numerical_cols = []\n",
    "    if \"Target\" in data_column_mapping:\n",
    "        numerical_cols.extend(data_column_mapping[\"Target\"])\n",
    "    if \"Regressor\" in data_column_mapping:\n",
    "        numerical_cols.extend(data_column_mapping[\"Regressor\"])\n",
    "\n",
    "    for col in numerical_cols:\n",
    "        if col in df.columns:\n",
    "            # Check if the column is already a numeric type.\n",
    "            # If not, attempt to cast to Float64 as a general numeric type.\n",
    "            # This prevents converting integers to floats if they are already correctly typed.\n",
    "            if not df[col].dtype.is_numeric():\n",
    "                df = df.with_columns(pl.col(col).cast(pl.Float64).alias(col))\n",
    "                print(f\"  Converted non-numeric '{col}' to Float64.\")\n",
    "            else:\n",
    "                print(f\"  '{col}' is already numeric (type: {df[col].dtype}). No conversion needed.\")\n",
    "\n",
    "    print(\"\\nDataFrame Schema after Pre-processing:\")\n",
    "    print(df.schema)         \n",
    "\n",
    "    return df               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466965b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def InferDataFrequency(df: pl.DataFrame, date_col: str, id_col: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Infers the most common frequency (in days) of the data based on the dates for each ID.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The input DataFrame.\n",
    "        date_col (str): The name of the date column.\n",
    "        id_col (str): The name of the identifier column to group by.\n",
    "\n",
    "    Returns:\n",
    "        Optional[float]: The inferred frequency in days, or None if it cannot be determined.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We calculate the difference in days between consecutive dates for each ID\n",
    "    # and find the most common difference (mode) to infer the frequency.\n",
    "    freq_df = (\n",
    "        df.select([pl.col(id_col), pl.col(date_col)])\n",
    "        .sort(id_col, date_col)\n",
    "        .group_by(id_col)\n",
    "        .agg(pl.col(date_col).diff().dt.total_days())\n",
    "        .explode(date_col)\n",
    "        .drop_nulls()\n",
    "    )\n",
    "    \n",
    "    if not freq_df.is_empty():\n",
    "        frequency = freq_df['Date'].mode()[0]\n",
    "        print(f\"  Inferred data frequency: {frequency} days.\")\n",
    "    else:\n",
    "        frequency = None\n",
    "        print(\" Could not determine data frequency.\")\n",
    "        raise ValueError(\"Could not determine data frequency.\")\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "def CreateMonthCyclicalEncoding(df: pl.DataFrame, date_col: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates cyclical features (sin, cos) for the month of the year.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The input DataFrame.\n",
    "        date_col (str): The name of the date column.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The DataFrame with added month_sin and month_cos columns.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Month of Year\n",
    "    df = df.with_columns([\n",
    "        pl.col(date_col).dt.month().alias(\"month_of_year\")\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        (np.pi * 2 * pl.col(\"month_of_year\") / 12).sin().alias(\"month_sin\"),\n",
    "        (np.pi * 2 * pl.col(\"month_of_year\") / 12).cos().alias(\"month_cos\")\n",
    "    ])\n",
    "    df = df.drop([\"month_of_year\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "def CreateWeekCyclicalEncoding(df: pl.DataFrame, date_col: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates cyclical features (sin, cos) for the week of the year.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The input DataFrame.\n",
    "        date_col (str): The name of the date column.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The DataFrame with added week_sin and week_cos columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.with_columns([\n",
    "        pl.col(date_col).dt.week().alias(\"week_of_year\")\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        (np.pi * 2 * pl.col(\"week_of_year\") / 52).sin().alias(\"week_sin\"),\n",
    "        (np.pi * 2 * pl.col(\"week_of_year\") / 52).cos().alias(\"week_cos\")\n",
    "    ])\n",
    "    df = df.drop([\"week_of_year\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def CreateDayCyclicalEncoding(df: pl.DataFrame, date_col: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates cyclical features (sin, cos) for the day of the year.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The input DataFrame.\n",
    "        date_col (str): The name of the date column.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The DataFrame with added day_of_year_sin and day_of_year_cos columns.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Day of Week\n",
    "    df = df.with_columns([\n",
    "        pl.col(date_col).dt.ordinal_day().alias(\"day_of_year\")\n",
    "    ])\n",
    "    df = df.with_columns([\n",
    "        (np.pi * 2 * pl.col(\"day_of_year\") / 365.25).sin().alias(\"day_sin\"),\n",
    "        (np.pi * 2 * pl.col(\"day_of_year\") / 365.25).cos().alias(\"day_cos\")\n",
    "    ])\n",
    "    df = df.drop(\"day_of_year\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_time_features(df: pl.DataFrame, date_col: str, id_col: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates time-series features based on the inferred data frequency.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): The input DataFrame.\n",
    "        date_col (str): The name of the date column.\n",
    "        id_col (str): The name of the identifier column.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The DataFrame with added time-based features.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Creating Time-wise Features ---\")\n",
    "   \n",
    "    frequency = InferDataFrequency(df, date_col, id_col)\n",
    "\n",
    "    # --- Feature Creation ---\n",
    "    if frequency <= 31:\n",
    "        df = CreateMonthCyclicalEncoding(df, date_col)\n",
    "        print(\" Created 'month_sin' and 'month_cos' features.\")\n",
    "    else:\n",
    "        print(\" Skipping 'month' features due to higher frequency.\")\n",
    "\n",
    "    # Week of Year\n",
    "    if frequency <= 7:\n",
    "        df = CreateWeekCyclicalEncoding(df, date_col)\n",
    "        print(\" Created 'week_sin' and 'week_cos' features.\")\n",
    "    else:\n",
    "        print(\" Skipping 'week' features due to higher frequency.\")\n",
    "    \n",
    "    # Day of Year\n",
    "    if frequency <= 1:\n",
    "        df = CreateDayCyclicalEncoding(df, date_col)\n",
    "        print(\" Created 'day_of_year_sin' and 'day_of_year_cos' features.\")\n",
    "    else:\n",
    "        print(\" Skipping 'day_of_year' features due to higher frequency.\")\n",
    "        \n",
    "    return df, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66fab247",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def FeatureEngineering(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the feature engineering process.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Preprocessed DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: DataFrame with all new features.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Feature Engineering ---\")\n",
    "    \n",
    "    id_col = data_column_mapping.get(\"ID\", [None])[0]\n",
    "    date_col = data_column_mapping.get(\"Date\", [None])[0]\n",
    "    target_col = data_column_mapping.get(\"Target\", [None])[0]\n",
    "\n",
    "    if not target_col or target_col not in df.columns:\n",
    "        raise ValueError(\"Target column is not defined or does not exist in the DataFrame.\")\n",
    "    if not date_col or date_col not in df.columns:\n",
    "        raise ValueError(\"Date column is not defined or does not exist in the DataFrame.\")\n",
    "    if not id_col or id_col not in df.columns:\n",
    "        raise ValueError(\"ID column is not defined or does not exist in the DataFrame.\")    \n",
    "\n",
    "    # Sorting is crucial for time-series features\n",
    "    if id_col and date_col and id_col in df.columns and date_col in df.columns:\n",
    "        df = df.sort(id_col, date_col)\n",
    "        print(f\" DataFrame sorted by '{id_col}' and '{date_col}'.\")\n",
    "\n",
    "    # Call feature creation functions\n",
    "    df, frequency = create_time_features(df, date_col, id_col)\n",
    "    # df = create_lags(df, target_col, id_col, lags = [1, 2, 3, 4])\n",
    "    # df = create_rolling_averages(df, target_col, id_col, window_size = 4)\n",
    "    \n",
    "    print(\"\\n--- Feature Engineering Complete ---\")\n",
    "    print(\"DataFrame Schema after Feature Engineering:\")\n",
    "    print(df.schema)\n",
    "    \n",
    "    return df, frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a008ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, frequency):\n",
    "\n",
    "    id_col = data_column_mapping.get(\"ID\", [None])[0]\n",
    "    date_col = data_column_mapping.get(\"Date\", [None])[0]\n",
    "    target_col = data_column_mapping.get(\"Target\", [None])[0]\n",
    "\n",
    "    lgb_params = {\n",
    "        'verbosity': -1,\n",
    "        'num_leaves': 512,\n",
    "    }\n",
    "\n",
    "    sales_model = MLForecast(\n",
    "        models={\n",
    "            'pred': lgb.LGBMRegressor(**lgb_params)\n",
    "        }, \n",
    "        freq='1w',\n",
    "        # lags=[1,2,3,4], \n",
    "        lag_transforms={\n",
    "            1: [RollingMean(window_size=4)],\n",
    "        },\n",
    "        # target_transforms=[Differences([24])],\n",
    "    )\n",
    "\n",
    "    sales_model.fit(df, \n",
    "                    id_col=id_col, \n",
    "                    time_col=date_col, \n",
    "                    target_col=target_col,\n",
    "                    static_features=[])\n",
    "\n",
    "    return sales_model\n",
    "\n",
    "def save_model(sales_model, model_path = 'sales_forecast_model.pkl'):\n",
    "    \"\"\"\n",
    "    Saves the trained MLForecast model to the specified path.\n",
    "    \n",
    "    Args:\n",
    "        sales_model (MLForecast): The trained MLForecast model.\n",
    "        model_path (str): The path where the model should be saved.\n",
    "    \"\"\"\n",
    "    \n",
    "    sales_model.save(model_path)\n",
    "\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def load_model( model_path = 'sales_forecast_model.pkl'):\n",
    "    \"\"\"\n",
    "    load the trained MLForecast model from the specified path.\n",
    "    \n",
    "    Args:\n",
    "         (str): base directory.\n",
    "        model_path (str): The path from which the model should be loaded.\n",
    "    \"\"\"\n",
    "    \n",
    "    sales_model = MLForecast.load(model_path)\n",
    "\n",
    "    return sales_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forecast_model():\n",
    "\n",
    "    df = GetTrainingData()\n",
    "\n",
    "    df = PreProcessDataType(df)\n",
    "\n",
    "    # Feature creation \n",
    "    df, frequency = FeatureEngineering(df)\n",
    "\n",
    "    # Train and save the model\n",
    "    sales_model = train_model(df, frequency)\n",
    "    save_model(sales_model)\n",
    "\n",
    "    print(\"\\n--- Forecast Model Training & Saving Complete ---\")\n",
    "\n",
    "def predict_using_forecast_model(h):\n",
    "\n",
    "    # get future weeks exogenous data\n",
    "    df = GetTestData()\n",
    "\n",
    "    df = PreProcessDataType(df)\n",
    "\n",
    "    # Feature creation \n",
    "    df, frequency = FeatureEngineering(df)\n",
    "\n",
    "    target_col = data_column_mapping.get(\"Target\", [None])[0]\n",
    "    X_df = df.drop(target_col)\n",
    "\n",
    "    sales_model = load_model()\n",
    "\n",
    "    # SRMIST: h is the number of weeks ahead that we are forecasting. \n",
    "    preds = sales_model.predict(h=h, X_df=X_df)\n",
    "\n",
    "    # SRMIST: This should be written into the DB. \n",
    "    preds.write_csv('predictions.csv')\n",
    "    \n",
    "    print(\"\\n--- Predictions done and saved. ---\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78116d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pre-processing Data Types ---\n",
      "  Converted 'Date' column to Date.\n",
      "  Converted 'Store' to String.\n",
      "  'Weekly_Sales' is already numeric (type: Float64). No conversion needed.\n",
      "  'Holiday_Flag' is already numeric (type: Int64). No conversion needed.\n",
      "  'Temperature' is already numeric (type: Float64). No conversion needed.\n",
      "  'Fuel_Price' is already numeric (type: Float64). No conversion needed.\n",
      "  'CPI' is already numeric (type: Float64). No conversion needed.\n",
      "  'Unemployment' is already numeric (type: Float64). No conversion needed.\n",
      "\n",
      "DataFrame Schema after Pre-processing:\n",
      "Schema({'Store': String, 'Date': Date, 'Weekly_Sales': Float64, 'Holiday_Flag': Int64, 'Temperature': Float64, 'Fuel_Price': Float64, 'CPI': Float64, 'Unemployment': Float64})\n",
      "\n",
      "--- Starting Feature Engineering ---\n",
      " DataFrame sorted by 'Store' and 'Date'.\n",
      "\n",
      "--- Creating Time-wise Features ---\n",
      "  Inferred data frequency: 7 days.\n",
      " Created 'month_sin' and 'month_cos' features.\n",
      " Created 'week_sin' and 'week_cos' features.\n",
      " Skipping 'day_of_year' features due to higher frequency.\n",
      "\n",
      "--- Feature Engineering Complete ---\n",
      "DataFrame Schema after Feature Engineering:\n",
      "Schema({'Store': String, 'Date': Date, 'Weekly_Sales': Float64, 'Holiday_Flag': Int64, 'Temperature': Float64, 'Fuel_Price': Float64, 'CPI': Float64, 'Unemployment': Float64, 'month_sin': Float64, 'month_cos': Float64, 'week_sin': Float64, 'week_cos': Float64})\n",
      "Model saved to sales_forecast_model.pkl\n",
      "\n",
      "--- Forecast Model Training & Saving Complete ---\n"
     ]
    }
   ],
   "source": [
    "# SRMIST: This function will have to be scheduled and we also should have an option to get this run on request. \n",
    "# SRMIST: This function creates and saves the model. \n",
    "train_forecast_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ad164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Pre-processing Data Types ---\n",
      "  Converted 'Date' column to Date.\n",
      "  Converted 'Store' to String.\n",
      "  'Weekly_Sales' is already numeric (type: Float64). No conversion needed.\n",
      "  'Holiday_Flag' is already numeric (type: Int64). No conversion needed.\n",
      "  'Temperature' is already numeric (type: Float64). No conversion needed.\n",
      "  'Fuel_Price' is already numeric (type: Float64). No conversion needed.\n",
      "  'CPI' is already numeric (type: Float64). No conversion needed.\n",
      "  'Unemployment' is already numeric (type: Float64). No conversion needed.\n",
      "\n",
      "DataFrame Schema after Pre-processing:\n",
      "Schema({'Store': String, 'Date': Date, 'Weekly_Sales': Float64, 'Holiday_Flag': Int64, 'Temperature': Float64, 'Fuel_Price': Float64, 'CPI': Float64, 'Unemployment': Float64})\n",
      "\n",
      "--- Starting Feature Engineering ---\n",
      " DataFrame sorted by 'Store' and 'Date'.\n",
      "\n",
      "--- Creating Time-wise Features ---\n",
      "  Inferred data frequency: 7 days.\n",
      " Created 'month_sin' and 'month_cos' features.\n",
      " Created 'week_sin' and 'week_cos' features.\n",
      " Skipping 'day_of_year' features due to higher frequency.\n",
      "\n",
      "--- Feature Engineering Complete ---\n",
      "DataFrame Schema after Feature Engineering:\n",
      "Schema({'Store': String, 'Date': Date, 'Weekly_Sales': Float64, 'Holiday_Flag': Int64, 'Temperature': Float64, 'Fuel_Price': Float64, 'CPI': Float64, 'Unemployment': Float64, 'month_sin': Float64, 'month_cos': Float64, 'week_sin': Float64, 'week_cos': Float64})\n",
      "\n",
      "--- Predictions done and saved. ---\n"
     ]
    }
   ],
   "source": [
    "# SRMIST: This function generates the prediction. \n",
    "# SRMIST: h is the number of weeks ahead that we want to forecast.\n",
    "h = 4\n",
    "predict_using_forecast_model(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716f795b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
